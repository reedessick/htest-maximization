#!/usr/bin/env python

"""a simple script to build a toy model of bias introduced by data selection that maximizes a detection statistic
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os

import numpy as np

import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt
plt.rcParams.update({
    'figure.subplot.left':0.05,
    'figure.subplot.right':0.95,
    'figure.subplot.top':0.95,
    'figure.subplot.bottom':0.20,
    'font.family': 'serif',
    'mathtext.fontset': 'dejavuserif',
    'mathtext.rm': 'serif',
})

from argparse import ArgumentParser

#-------------------------------------------------

figsize = (4, 4)
fontsize=12

#-------------------------------------------------

def compute_bayes(minx, count, M=10):
    """compute the bayes factor between a model that has a flat prior on the mean (restricted to be positive) and a model where the mean is zero
    B = (exp(count*min(x)) - 1)/count
    """
    minx = np.where(minx<M, minx, M)

    return (np.exp(count*minx) - 1.0) / (count*M)

def plot_ordered_bayes(bayes, minxs, counts=None, truth=None, fig=None):
    """make a plot of how the bayes factor changes as we include more ordered data
    """

    if fig is None:
        fig = plt.figure(figsize=figsize)
        ax = plt.subplot(2,1,1)
        AX = plt.subplot(2,1,2)

        ymin = -1
        ymax = -1

        YMIN = 0
        YMAX = 0

    else:
        fig, ax, AX = fig
        ymin, ymax = ax.get_ylim()
        YMIN, YMAX = AX.get_ylim()

    bayes = np.log10(bayes)

    low = min(bayes)
    high = max(bayes)
    diff = (high - low)*0.05
    low -= diff
    high += diff

    ymin = min(low, ymin)
    ymax = max(high, ymax)

    low = min(minxs)
    high = max(minxs)
    diff = (high - low)*0.05
    low -= diff
    high += diff

    YMIN = min(low, YMIN)
    YMAX = max(high, YMAX)

    if counts is None:
        counts = np.arange(len(bayes)) + 1

    kwargs = dict(
#        linestyle='none',
        marker='.',
        markersize=2,
        alpha=0.25,
        color='b',
    )

    # plot bayes factors
    ax.plot(counts, bayes, **kwargs)
    ax.set_ylim(ymin=ymin, ymax=ymax)

    # plot minxs
    AX.plot(counts, minxs, **kwargs)
    AX.set_ylim(ymin=YMIN, ymax=YMAX)

    if truth is not None:
        AX.plot([counts[0], counts[-1]], [truth]*2, linestyle='dashed', color='grey')

    # decorate
    ax.set_ylabel('$\log_{10} \mathcal{B}^{m>0}_{m=0}$', fontsize=fontsize)
    AX.set_ylabel('running\nminimum', fontsize=fontsize)

    plt.setp(ax.get_xticklabels(), visible=False)
    AX.set_xlabel('number of data', fontsize=fontsize)

    dx = (counts[-1] - counts[0])*0.02
    ax.set_xlim(xmin=counts[0]-dx, xmax=counts[-1]+dx)
    AX.set_xlim(ax.get_xlim())

    # location of maximum
    ind = np.argmax(bayes)
    kwargs = dict(linestyle='solid', color='grey', alpha=0.50)

    xmin, xmax = ax.get_xlim()
    ymin, ymax = ax.get_ylim()
    ax.plot([xmin, xmax], [bayes[ind]]*2, **kwargs)
    ax.plot([counts[ind]]*2, [ymin, bayes[ind]], **kwargs)

    ymin, ymax = AX.get_ylim()
    AX.plot([counts[ind]]*2, [ymin, ymax], **kwargs)
    AX.plot([xmin, xmax], [minxs[ind]]*2, **kwargs)

    # aesthetic things

    for _ in [ax, AX]:
        _.tick_params(direction='in')

    plt.subplots_adjust(
        left=0.15,
        right=0.95,
        top=0.98,
        bottom=0.10,
        wspace=0.03,
        hspace=0.03,
    )

    # return
    return fig, ax, AX

def plot_ratios(alldata, ordered):
    """make a plot of the distributions of these values and their ratio
    """
    fig = plt.figure()

    ax = plt.subplot(1,2,1)
    AX = plt.subplot(1,2,2)

    nbins = max(10, int(len(alldata)**0.5))
    bins = np.linspace(np.log10(np.min([alldata, ordered])), np.log10(np.max([alldata, ordered])), nbins+1)

    # plot the distributions of each set
    ax.hist(np.log10(alldata), bins=bins, histtype='step', density=True, label='all data', color='b')
    ax.hist(np.log10(ordered), bins=bins, histtype='step', density=True, label='maximized', color='r')

    ax.set_xlabel('$\log_{10} \mathcal{B}^{\mu>0}_{\mu=0}$')
    ax.set_yticks([])

    # plot the ratios
    AX.hist(np.log10(ordered) - np.log10(alldata), bins=nbins, histtype='step', density=True, color='m')

    AX.set_xlabel('$\log_{10} \mathcal{B}_\mathrm{max} - \log_{10} \mathcal{B}_\mathrm{all}$')
    AX.set_yticks([])

    # decorate
    for _ in [ax, AX]:
        _.tick_params(direction='in')

    plt.subplots_adjust(
        left=0.05,
        right=0.95,
        top=0.98,
        bottom=0.10,
        wspace=0.03,
        hspace=0.03,
    )

    ax.legend(loc='best')

    # return
    return fig

def plot_estimators(alldata, ordered, truth=None):
    """make a plot of the MLE estimators to look for biases
    """
    fig = plt.figure()

    ax1 = plt.subplot(2,2,1)
    ax2 = plt.subplot(2,2,3)
    ax3 = plt.subplot(2,2,4)

    nbins = max(10, int(len(alldata)**0.5))

    # figure out bounds
    min1 = np.min(alldata)
    if truth is not None:
        min1 = min(min1, truth)
    max1 = np.max(alldata)
    d = (max1-min1)*0.1
    min1 -= d
    max1 += d

    min2 = np.min(ordered)
    if truth is not None:
        min2 = min(min2, truth)
    max2 = np.max(ordered)
    d = (max2 - min2)*0.1
    min2 -= d
    max2 += d

    # make marginal distributions
    ax1.hist(alldata, bins=np.linspace(min1, max1, nbins+1), density=True, histtype='step')
    ax3.hist(ordered, bins=np.linspace(min2, max2, nbins+1), density=True, histtype='step', orientation='horizontal')

    # make joint scatter plot
    ax2.plot(alldata, ordered, linestyle='none', marker='.', alpha=0.10)

    # decorate
    for _ in [ax1, ax2, ax3]:
        _.tick_params(direction='in')

    ax1.set_xlim(xmin=min1, xmax=max1)
    ax3.set_ylim(ymin=min2, ymax=max2)

    if truth is not None:
        ylim = ax1.get_ylim()
        ax1.plot([truth]*2, ylim, color='grey', linestyle='dashed')
        ax1.set_ylim(ylim)

        xlim = ax3.get_xlim()
        ax3.plot(xlim, [truth]*2, color='grey', linestyle='dashed')
        ax3.set_xlim(xlim)

        ax2.plot([truth]*2, [min2, max2], color='grey', linestyle='dashed')
        ax2.plot([min1, max1], [truth]*2, color='grey', linestyle='dashed')

    ax2.set_xlim(ax1.get_xlim())
    ax2.set_ylim(ax3.get_ylim())

    ax2.set_xlabel('$\hat{\mu}$ with all data')
    ax2.set_ylabel('$\hat{\mu}$ with downselected data')

    ax1.set_yticks([])
    ax3.set_xticks([])

    plt.setp(ax1.get_xticklabels(), visible=False)
    plt.setp(ax3.get_yticklabels(), visible=False)

    plt.subplots_adjust(
        left=0.10,
        right=0.95,
        top=0.98,
        bottom=0.10,
        wspace=0.03,
        hspace=0.03,
    )

    # return
    return fig

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('-m', '--true-shift', default=0.1, type=float)

parser.add_argument('-n', '--num-observations', default=100, type=int)
parser.add_argument('-N', '--num-trials', default=10, type=int)

parser.add_argument('-o', '--output-dir', default='.', type=str)
parser.add_argument('-t', '--tag', default='', type=str)
parser.add_argument('-p', '--plot-individual-trials', default=False, action='store_true')

parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-V', '--Verbose', default=False, action='store_true')

parser.add_argument('-s', '--seed', default=None, type=int)

args = parser.parse_args()

args.verbose |= args.Verbose

args.output_dir = os.path.abspath(args.output_dir)
if not os.path.exists(args.output_dir):
    os.makedirs(args.output_dir)

if args.tag:
    args.tag = "_"+args.tag

#-------------------------------------------------

if args.seed is not None:
    if args.verbose:
        print('setting numpy.random.seed=%d'%args.seed)
    np.random.seed(args.seed)

#-------------------------------------------------

# set up arrays that track statistics
bayes = np.empty(args.num_observations, dtype=float) ### re-used within loop
minxs = np.empty(args.num_observations, dtype=float)
counts = np.arange(args.num_observations) + 1

alldata_bayes = np.empty(args.num_trials, dtype=float) ### the bayes factors obtained using all data
alldata_minxs = np.empty(args.num_trials, dtype=float) ### the associated min(x)

ordered_bayes = np.empty(args.num_trials, dtype=float) ### the bayes factors maximized over data included
ordered_minxs = np.empty(args.num_trials, dtype=float) ### the associated min(x)
ordered_counts = np.empty(args.num_trials, dtype=int)  ### the associated number of observations retained

# iterating through trials
if args.verbose:
    print('generating simulated data')

if args.plot_individual_trials:
    FIG = None

for trial in range(args.num_trials):
    if args.Verbose:
        print('trial: %4d / %4d'%(trial+1, args.num_trials))

    # generate data
    if args.Verbose:
        print('    generating %d observations: x ~ exp(-(x-%.3f))*Theta(%.4f<x)'%(args.num_observations, args.true_shift, args.true_shift))

    data = args.true_shift - np.log(1.0 - np.random.random(size=args.num_observations))
    data = data[np.argsort(data)][::-1] # sort data (largest to smallest)

    if args.Verbose:
        print('    computing detection statistic')
    minxs[:] = data[:]
    bayes[:] = compute_bayes(minxs, counts)

    # store data
    alldata_bayes[trial] = bayes[-1] ### when we include all data
    alldata_minxs[trial] = minxs[-1]

    ind = np.argmax(bayes) ### when we include ordered data up to maximum of detection statistic
    ordered_bayes[trial] = bayes[ind]
    ordered_minxs[trial] = minxs[ind]
    ordered_counts[trial] = counts[ind]

    # plot if requested
    if args.plot_individual_trials:
        if args.Verbose:
            print('    plotting detection statistic vs. number of ordered observations')
        fig, _, _ = plot_ordered_bayes(bayes, minxs, counts=counts, truth=args.true_shift)
        for figtype in ['png', 'pdf']:
            figname = os.path.join(args.output_dir, 'univariate-exponential%s-trial-%d.%s'%(args.tag, trial, figtype))
            if args.Verbose:
                print('        saving: '+figname)
            fig.savefig(figname)
        plt.close(fig)

        FIG = plot_ordered_bayes(bayes, minxs, counts=counts, truth=None, fig=FIG)

if args.plot_individual_trials:
    figname = os.path.join(args.output_dir, 'univariate-exponential%s-trials.png'%(args.tag))
    if args.verbose:
        print('saving: '+figname)
    FIG = FIG[0]
    FIG.savefig(figname)
    plt.close(FIG)

#------------------------

### save data
path = os.path.join(args.output_dir, 'univariate-exponential%s.csv.gz'%(args.tag))
if args.verbose:
    print('saving data to: '+path)
data = np.transpose([
    alldata_bayes,
    alldata_minxs,
    np.ones(args.num_trials)*args.num_observations,
    ordered_bayes,
    ordered_minxs,
    ordered_counts,
])
header = ','.join([
    'alldata_bayes',
    'alldata_minxs',
    'alldata_counts',
    'ordered_bayes',
    'ordered_minxs',
    'ordered_counts',
])
np.savetxt(path, data, delimiter=',', comments='', header=header)

#------------------------

# make general summary plots
if args.verbose:
    print('generating summary plots')

# ratios of bayes factors
if args.verbose:
    print('plotting Bayes factors')
fig = plot_ratios(alldata_bayes, ordered_bayes)
figname = os.path.join(args.output_dir, 'univariate-exponential%s-bayes-ratio.png'%(args.tag))
if args.verbose:
    print('    saving: '+figname)
fig.savefig(figname)
plt.close(fig)

### NOTE:
###     does the difference in counts correlate with the increased bayes factor?
###     maybe we want to investigate this further?

# MAP (really MLE) values from included data
if args.verbose:
    print('plotting estimates of the distribution\'s minimum')
fig = plot_estimators(alldata_minxs, ordered_minxs, truth=args.true_shift)
figname = os.path.join(args.output_dir, 'univariate-exponential%s-mle-estimates.png'%(args.tag))
if args.verbose:
    print('    saving: '+figname)
fig.savefig(figname)
plt.close(fig)
